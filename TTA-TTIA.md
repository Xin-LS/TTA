# Test-Time Instance Adaptation

<b>Test-Time Input Adaptation (TTIA) refers to a category of techniques designed to address the input distribution shift problem, where the feature distribution encountered during model deployment frequently diverges from the distribution observed in the training data. Conventional approaches typically struggle to maintain robust performance and prediction reliability under such conditions. <p>
This collection features representative papers from recent years in this field, spanning diverse applications such as medical image classification, long-tailed recognition, and federated learning.
# Test-Time Adaptation & Domain Generalization Papers

## Image classification
---

### `SSGen` [Xiao et al., **ICLR 2022**]  
**Learning to generalize across domains on single test samples**  
[ğŸ“„ PDF](https://arxiv.org/abs/2202.08045) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=10799367073706985191&hl=en) Â· [ğŸ’» CODE](https://github.com/zzzx1224/SingleSampleGeneralization-ICLR2022)

<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract
We strive to learn a model from a set of source domains that generalizes well to unseen target domains. The main challenge in such a domain generalization scenario is the unavailability of any target domain data during training, resulting in the learned model not being explicitly adapted to the unseen target domains. We propose learning to generalize across domains on single test samples. We leverage a meta-learning paradigm to learn our model to acquire the ability of adaptation with single samples at training time so as to further adapt itself to each single test sample at test time. We formulate the adaptation to the single test sample as a variational Bayesian inference problem, which incorporates the test sample as a conditional into the generation of model parameters. The adaptation to each test sample requires only one feed-forward computation at test time without any fine-tuning or self-supervised training on additional data from the unseen domains. Extensive ablation studies demonstrate that our model learns the ability to adapt models to each single sample by mimicking domain shifts during training. Further, our model achieves at least comparableâ€“ and often betterâ€“ performance than state-of-the-art methods on multiple benchmarks for domain generalization 1.

#### ğŸ¯ Contributions
To be specific, we build our model under the meta-learning framework and formulate the single sample generalization as a variational inference problem. In the training stage, we divide the source domains into several meta-source domains and a meta-target domain and explore the adaptive model by incorporating the information of the meta-target sample into the generation of the model parameters. For any given meta-target sample, we propose a variational distribution generated by this sample and the meta-source data to approximate the model distribution obtained by the meta-target data. In the test phase, the adapted models for the samples from the real target domains are generated on the fly by the variational model distribution. The random splits of the meta-source and meta-target domains expose the model to domain shifts and mimic the real generalization process from source domains to the target domain. Thus, the model is endowed with the ability to adapt to any unseen sample by end-to-end training with the source data only. By doing so, our method does not need to introduce any extra target data or fine-tuning operations on the target domain.


#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/SSGEN.png" alt="SSGEN Overview">
  <img src="images/TTIA/SSGEN1.png" alt="SSGEN Overview">
</p>
</details>

---

### `MEMO` [Zhang et al., **NeurIPS 2022**]  
**MEMO: Test time robustness via adaptation and augmentation**  
[ğŸ“„ PDF](https://openreview.net/forum?id=XrGEkCOREX2) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=1448618539109048791&hl=en) Â· [ğŸ’» CODE](https://github.com/zhangmarvin/memo)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>

#### ğŸ§  Abstract
While deep neural networks can attain good accuracy on in-distribution test points, many applications require robustness even in the face of unexpected perturbations in the input, changes in the domain, or other sources of distribution shift. We study the problem of test time robustification, i.e., using the test input to improve model robustness. Recent prior works have proposed methods for test time adaptation, however, they each introduce additional assumptions, such as access to multiple test points, that prevent widespread adoption. In this work, we aim to study and devise methods that make no assumptions about the model training process and are broadly applicable at test time. We propose a simple approach that can be used in any test setting where the model is probabilistic and adaptable: when presented with a test example, perform different data augmentations on the data point, and then adapt (all of) the model parameters by minimizing the entropy of the modelâ€™s average, or marginal, output distribution across the augmentations. Intuitively, this objective encourages the model to make the same prediction across different augmentations, thus enforcing the invariances encoded in these augmentations, while also maintaining confidence in its predictions. In our experiments, we evaluate two baseline ResNet models, two robust ResNet-50 models, and a robust vision transformer model, and we demonstrate that this approach achieves accuracy gains of 1-8% over standard model evaluation and also generally outperforms prior augmentation and adaptation strategies. For the setting in which only one test point is available, we achieve state-of-the-art results on the ImageNet-C, ImageNet-R, and, among ResNet-50 models, ImageNet-A distribution shift benchmarks.

#### ğŸ¯ Contributions
We refer to the proposed method as marginal entropy minimization with one test point (MEMO), and this is the primary contribution of our work. MEMO makes direct use of pretrained models without any assumptions about their particular training procedure or architecture, while requiring only a single test input for adaptation. In Section 4, we demonstrate empirically that MEMO consistently improves the performance of ResNet [11] and vision transformer [7] models on several challenging ImageNet distribution shift benchmarks, achieving several new state-of-the-art results for these models in the setting in which only one test point is available. MEMO consistently outperforms non-adaptive marginal distribution predictions (between 1â€“10% improvement) on the ImageNet-C [12] and ImageNet-R [14] test sets, indicating that adaptation plays a crucial role in improving predictive accuracy. MEMO encourages both invariance across augmentations and confident predictions, and an ablation study in Section 4 shows that both components are important for maximal performance gains. Also, MEMO is, to the best of our knowledge, the first adaptation method to improve performance (by 1â€“4% over standard model evaluation) on the ImageNet-A test set [15].



#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/MEMO.png" alt="SSGEN Overview">
  <br>
  <img src="images/TTIA/MEMO1.png" alt="SSGEN Overview">
</p>
</details>
---

### `TTT-MAE` [Gandelsman et al., **NeurIPS 2022**]  
**Test-time training with masked autoencoders**  
[ğŸ“„ PDF](https://openreview.net/forum?id=SHMi1b7sjXk) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=2544097260576053446&hl=en) Â· [ğŸ’» CODE](https://github.com/yossigandelsman/test_time_training_mae)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>

#### ğŸ§  Abstract
Test-time training adapts to a new test distribution on the fly by optimizing a model for each test input using self-supervision. In this paper, we use masked autoencoders for this one-sample learning problem. Empirically, our simple method improves generalization on many visual benchmarks for distribution shifts. Theoretically, we characterize this improvement in terms of the bias-variance trade-off

#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/TTMAE.png" alt="TTMAE Overview">
</p>

</details>

---

### `DDG` [Sun et al., **IJCAI 2022**]  
**Dynamic domain generalization**  
[ğŸ“„ PDF](https://arxiv.org/abs/2205.13913) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=4234489258058037285&hl=en) Â· [ğŸ’» CODE](https://github.com/MetaVisionLab/DDG)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract
Domain generalization (DG) is a fundamental yet very challenging research topic in machine learning. The existing arts mainly focus on learning domain-invariant features with limited source domains in a static model. Unfortunately, there is a lack of training-free mechanism to adjust the model when generalized to the agnostic target domains. To tackle this problem, we develop a brand-new DG variant, namely Dynamic Domain Generalization (DDG), in which the model learns to twist the network parameters to adapt the data from different domains. Specifically, we leverage a meta-adjuster to twist the network parameters based on the static model with respect to different data from different domains. In this way, the static model is optimized to learn domain-shared features, while the meta-adjuster is designed to learn domain-specific features. To enable this process, DomainMix is exploited to simulate data from diverse domains during teaching the meta-adjuster to adapt the upcoming agnostic target domains. This learning mechanism urges the model to generalize to different agnostic target domains via adjusting the model without training. Extensive experiments demonstrate the effectiveness of our proposed method.

#### ğŸ¯ Contributions
We propose a new DG variant, **Dynamic Domain Generalization (DDG)**. As shown in Figure 1, different from DA, DG, as well as test-time DG methods, the proposed DDG is attached with a **meta-adjuster**, which learns to adapt novel domains during pre-training and twists the model during testing without any fine-tuning. To drive the process of learning to adapt, we need to collect training data from numerous novel domains, while in reality we are usually hindered by limited source domains. A simple yet friendly solution is to simulate novel samples from the limited source domains via a random convex interpolation among different source domains â€” termed **DomainMix**. In this way, each simulated sample is restricted to a unique domain. As a consequence, the domain-aware meta-adjuster can be relaxed into an **instance-aware meta-adjuster**, which modulates the network parameters per instance.

Additionally, the model more easily adapts from source domains to agnostic target domains with undefinable domain distinction, by discarding the utilization of domain labels during the optimization of the meta-adjuster. Beyond the optimization pipeline, another critical factor is how to **design the meta-adjuster**. To disentangle domain-shared and domain-specific features, network parameters are **decoupled into a static part and a dynamic part**, the latter generated per instance by the meta-adjuster. The dynamic parameters are decomposed into a linear combination of several **kernel templates** with low-dimensional dynamic coefficients. These coefficients are generated dynamically by the meta-adjuster from instance embeddings. As shown in Figure 3, the kernel templates are designed as **four asymmetric kernels** to strengthen the spatial and channel structure, regularizing the meta-adjuster to generate diverse parameters capable of adapting to a wide range of unseen samples.


#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/DDG.png" alt="DDG Overview">
  <br>
  <img src="images/TTIA/DDG1.png" >
  <br>
  <img src="images/TTIA/DDG2.png" >
</p>
</details>
---

### `TAF-Cal` [Zhao et al., **IJCAI 2022**]  
**Test-time fourier style calibration for domain generalization**  
[ğŸ“„ PDF](https://arxiv.org/abs/2205.06427) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=15047408040728759993&hl=en) Â· [ğŸ’» CODE](https://github.com/xingchenzhao/TAF-Cal)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract
The topic of generalizing machine learning models learned on a collection of source domains to unknown target domains is challenging. While many domain generalization (DG) methods have achieved promising results, they primarily rely on the source domains at train-time without manipulating the target domains at test-time. Thus, it is still possible that those methods can overfit to source domains and perform poorly on target domains. Driven by the observation that domains are strongly related to styles, we argue that reducing the gap between source and target styles can boost modelsâ€™ generalizability. To solve the dilemma of having no access to the target domain during training, we introduce Test-time Fourier Style Calibration (TF-Cal) for calibrating the target domain style on the fly during testing. To access styles, we utilize Fourier transformation to decompose features into amplitude (style) features and phase (semantic) features. Furthermore, we present an effective technique to Augment Amplitude Features (AAF) to complement TF-Cal. Extensive experiments on several popular DG benchmarks and a segmentation dataset for medical images demonstrate that our method outperforms state-of-the-art methods.

#### ğŸ¯ Contributions
In this paper, we propose a novel yet simple method called Test-time Fourier Style Calibration (TF-Cal) to calibrate the target style features at inference-time. Our method is driven by the assumption that the lack of generalizability is due to the difference in styles of images (e.g., sketches, cartoon, photo) between the source and target [Zhou et al., 2021]. Based on this idea, we employ Fourier transformation to decompose latent features from early CNN layers into amplitude features and phase features. The amplitude encodes the intensities (style information), while the phase encodes the spatial positions (semantic information) [Piotrowski and Campbell, 1982]. To achieve test-time style calibration, we propose to convexly calibrate the target amplitude features using the source amplitude prototype estimated at train-time. Hence we narrow the style gap between the target and source domains on the fly when evaluating, while retaining the key semantic feature for classification. We additionally show that increasing the diversity of features can complement TF-Cal to further boost modelsâ€™ generalizability based on the convex hull theory proposed by [Albuquerque et al., 2019]. Inspired by [Xu et al., 2021] which augments amplitude in image space, we propose augmenting amplitude in feature space (AAF) that diversifies higher-level styles, while preserving semantics. Then we have the Test-time Augmentated Fourier Style Calibration (TAF-Cal) by combining TF-Cal and AAF. Moreover, our algorithm does not require domain labels, allowing for more data collection flexibility.

#### ğŸ“‚ Datasets
<p>
For the white matter hyperintensity segmentation task, we use the MICCAI WMH Challenge dataset [Kuijf et al., 2019], which includes three domains: Utrecht, Amsterdam, and Singapore. Each domain contains 20 subjects. For each subject, Utrecht and Singapore provide 47 slices, while Amsterdam provides 82 slices. The primary domain shift arises from differences in scanner hardware and imaging protocols across the centers.
</p><br>

#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/TAF-Cal.png" alt="TAF-Cal Overview">
</p>
</details>
---

### `TTCP++` [Sarkar et al., **WACV 2022**]  
**Leveraging test-time consensus prediction for robustness against unseen noise**  
[ğŸ“„ PDF](https://openaccess.thecvf.com/content/WACV2022/html/Sarkar_Leveraging_Test-Time_Consensus_Prediction_for_Robustness_Against_Unseen_Noise_WACV_2022_paper.html) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=3457983965127110405&hl=en)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract
We propose a method to improve DNN robustness against unseen noisy corruptions, such as Gaussian noise, Shot Noise, Impulse Noise, Speckle noise with different levels of severity by leveraging ensemble technique through a consensus-based prediction method using self-supervised learning at inference time. We also propose to enhance the model training by considering other aspects of the issue, i.e., noise in data and better representation learning, which shows even better generalization performance with the consensus-based prediction strategy. We report results of each noisy corruption on the standard CIFAR10-C and ImageNet-C benchmarks, which show significant boost in performance over previous methods. We also introduce results for MNIST-C and TinyImageNet-C to show the usefulness of our method across datasets of different complexities to provide robustness against unseen noise. We show results with different architectures to validate our method against other baseline methods and also conduct experiments to show the usefulness of each part of our method.

#### ğŸ¯ Contributions
- We propose a novel **Test-Time Consensus Prediction (TTCP)** strategy to achieve better model robustness through improved generalization performance against unseen noise.
- We propose an extended framework, **TTCP++**, to exploit quantized latents and knowledge distillation in the training phase, further boosting the performance of the proposed TTCP method on unseen noise.
- Our results on **CIFAR10-C** and **ImageNet-C** show significant improvements over previous methods based on improved training. We also study our method on **MNIST-C** and **TinyImageNet-C** datasets â€” the first such results in this context â€” and report strong performance.
- We perform consistently against all kinds of noise on CIFAR10-C and ImageNet-C compared to augmentation-based methods, **even without any data augmentation and using only clean training data**.
- We present detailed **ablation studies** showing the usefulness of each component in our overall **TTCP++** framework.

#### ğŸ–¼ï¸ Method Overview
<p align="center">
</p>
  <img src="images/TTIA/TTCP.png" >
  </p>
  <img src="images/TTIA/TTCP1.png" >
  </p>
  <img src="images/TTIA/TTCP2.png" >
</p>
</details>
---

### `TTN` [Lim et al., **ICLR 2023**]  
**TTN: A domain-shift aware batch normalization in test-time adaptation**  
[ğŸ“„ PDF](https://openreview.net/forum?id=EQfeudmWLQ) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=12984514498411836030&hl=en)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract
This paper proposes a novel batch normalization strategy for test-time adaptation.  
Recent test-time adaptation (TTA) methods heavily rely on modified batch normalization, particularly **Transductive Batch Normalization (TBN)**, which recalculates the mean and variance from the test batch rather than using the running statistics from source data as in **Conventional Batch Normalization (CBN)**. Although TBN mitigates performance degradation under domain shift, it suffers when assumptions like large and i.i.d. test batches are violated.  
We identify a trade-off between CBN and TBN and introduce **Test-Time Normalization (TTN)** â€” a method that interpolates between CBN and TBN using layer-wise, domain-shift sensitivity-based weights. TTN is robust across a wide range of test batch sizes and evaluation scenarios. Moreover, TTN can be integrated into other TTA frameworks to further boost their performance. Extensive experiments demonstrate that TTN achieves state-of-the-art results across multiple benchmarks.

#### ğŸ¯ Contributions
- We propose a **domain-shift-aware Test-Time Normalization (TTN)** layer that interpolates between source (CBN) and test (TBN) statistics using channel-wise weights, dynamically adjusted based on domain-shift sensitivity per BN layer.
- TTN **requires no modification** to training or test-time schemes and can be directly applied to existing TTA methods. It significantly improves performance across a wide range of test batch sizes (from 200 to 1) and evaluation settings including:
  - **Stationary domain adaptation**
  - **Continuously changing domains**
  - **Mixed domain scenarios**
- We demonstrate TTNâ€™s effectiveness in both **image classification** and **semantic segmentation** tasks across diverse datasets.

#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/TTN.png" >
</p>
  <img src="images/TTIA/TTN1.png" >
</p>
 <img src="images/TTIA/TTN2.png" >
</p>
</details>
---

### `ESA` [Xiao et al., **ICLR 2023**]  
**Energy-based test sample adaptation for domain generalization**  
[ğŸ“„ PDF](https://openreview.net/forum?id=3dnrKbeVatv) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=3027943185987486652&hl=en)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract  
In this paper, we propose energy-based sample adaptation at test time for domain generalization. Where previous works adapt their models to target domains, we adapt the unseen target samples to source-trained models. To this end, we design a discriminative energy-based model, which is trained on source domains to jointly model the conditional distribution for classification and data distribution for sample adaptation. The model is optimized to simultaneously learn a classifier and an energy function. To adapt target samples to source distributions, we iteratively update the samples by energy minimization with stochastic gradient Langevin dynamics. Moreover, to preserve the categorical information in the sample during adaptation, we introduce a categorical latent variable into the energy-based model. The latent variable is learned from the original sample before adaptation by variational inference and fixed as a condition to guide the sample update. Experiments on six benchmarks for classification of images and microblog threads demonstrate the effectiveness of our proposal.

#### ğŸ¯ Contributions  
In this paper, we propose energy-based test sample adaptation for domain generalization. The method is motivated by the fact that energy-based models (Hinton, 2002; LeCun et al., 2006) flexibly model complex data distributions and allow for efficient sampling from the modeled distribution by Langevin dynamics (Du & Mordatch, 2019; Welling & Teh, 2011). Specifically, we define a new discriminative energy-based model as the composition of a classifier and a neural-network-based energy function in the data space, which are trained simultaneously on the source domains. The trained model iteratively updates the representation of each target sample by gradient descent of energy minimization through Langevin dynamics, which eventually adapts the sample to the source data distribution. The adapted target samples are then predicted by the classifier that is simultaneously trained in the discriminative energy-based model. For both efficient energy minimization and classification, we deploy the energy functions on the input feature space rather than the raw images.

#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/ESA.png" >
</p>
  <img src="images/TTIA/ESA1.png" >
</p>
 <img src="images/TTIA/ESA2.png" >
</p>
</details>
---

### `TSB` [Park et al., **ICML 2023**]  
**Test-time style shifting: Handling arbitrary styles in domain generalization**  
[ğŸ“„ PDF](https://arxiv.org/abs/2306.04911)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract  
In domain generalization (DG), the target domain is unknown when the model is being trained, and the trained model should successfully work on an arbitrary (and possibly unseen) target domain during inference. This is a difficult problem, and despite active studies in recent years, it remains a great challenge. In this paper, we take a simple yet effective approach to tackle this issue. We propose test-time style shifting, which shifts the style of the test sample (that has a large style gap with the source domains) to the nearest source domain that the model is already familiar with, before making the prediction. This strategy enables the model to handle any target domains with arbitrary style statistics, without additional model update at test-time. Additionally, we propose style balancing, which provides a great platform for maximizing the advantage of test-time style shifting by handling the DG-specific imbalance issues. The proposed ideas are easy to implement and successfully work in conjunction with various other DG schemes. Experimental results on different datasets show the effectiveness of our methods.

#### ğŸ¯ Contributions  
In this paper, we take a simple yet effective approach to improve the DG performance when there is a significant domain shift between the source and target domains. Specifically, in order to handle arbitrary target domains during inference, we propose test-time style shifting, which shifts the style of the test sample (that has a large style gap with the source domains) to the nearest source domain that the model is already familiar with, before making the prediction. Note that our scheme only performs style shifting in the style-space and thus does not require any model updates at test-time. Moreover, our test-time style shifting does not require additional changes in the model architecture or the objective function, making our scheme to be more compatible with any tasks/models.  
In order to maximize the effectiveness of test-time style shifting, the model should be well-trained on the styles of the source domains. Motivated by this, we also propose style balancing, which provides a great platform to increase the potential of test-time style shifting by handling the DG-specific imbalance issues. Note that in DG scenarios with multiple domains, the imbalance issues have different characteristics compared to the traditional class imbalance problem in a single domain; when a specific domain lacks certain classes, it turns out, as will seen in Section 5.3, that existing methods based on resampling or reweighting fail to handle these DG-specific imbalance issues.  
Our proposed style balancing handles this issue by choosing the sample that has similar style statistics to other samples (and thus has a similar role compared to others) in the same domain, and converting the style of this sample to another domain; this improves the domain diversity per classes during training by compensating for the missing classes in each domain.  
Our test-time style shifting and style balancing work in a highly complementary fashion; style balancing plays a key role in improving the performance of test-time style shifting by exposing the model to various styles per classes during training. Moreover, removing one of these components can degrade the performance in practice having (i) DG-specific imbalance issues and (ii) large domain shift between source and target at the same time.  
Our solution is compatible with not only the style-augmentation based DG schemes (e.g., MixStyle, DSU, EFDMix) that operate in the style space as ours, but also other DG ideas relying on domain alignment or meta-learning. Extensive experimental results on various DG benchmarks show the improved performance of our scheme over existing methods.

#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/TSB.png" >
</p>
  <img src="images/TTIA/TSB1.png" >
</p>
</details>
---

### `PromptAlign` [Samadh et al., **NeurIPS 2023**]  
**Align your prompts: Test-time prompting with distribution alignment for zero-shot generalization**  
[ğŸ“„ PDF](https://arxiv.org/abs/2311.01459) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=3235088620563898394&hl=en) Â· [ğŸ’» CODE](https://github.com/jameelhassan/PromptAlign)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract  
The promising zero-shot generalization of vision-language models such as CLIP has led to their adoption using prompt learning for numerous downstream tasks. Previous works have shown test-time prompt tuning using entropy minimization to adapt text prompts for unseen domains. While effective, this overlooks the key cause for performance degradation to unseen domainsâ€“ distribution shift. In this work, we explicitly handle this problem by aligning the out-of-distribution (OOD) test sample statistics to those of the source data using prompt tuning. We use a single test sample to adapt multi-modal prompts at test time by minimizing the feature distribution shift to bridge the gap in the test domain. Evaluating against the domain generalization benchmark, our method improves zero-shot top-1 accuracy beyond existing prompt-learning techniques, with a 3.08% improvement over the baseline MaPLe. In cross-dataset generalization with unseen categories across 10 datasets, our method improves consistently across all datasets compared to the existing state-of-the-art. Our source code and models are available at https://jameelhassan.github.io/promptalign/

#### ğŸ¯ Contributions  
â€¢ The proposed strategy formulates a distribution alignment loss that utilizes offline computed source data statistics to encourage the test sample token distributions to be aligned with the source data token distributions. We harmonically combine the benefits of token distribution alignment and entropy minimization using a multi-modal prompt learning approach.  
â€¢ Since CLIP-pre-training data is not publicly released, we study the statistics of ImageNet as a possible candidate for the source distribution, and our empirical results show that ImageNet is an effective proxy source dataset for large-scale V-L models such as CLIP.  
â€¢ We validate our method PromptAlign through extensive experiments in domain generalization and cross-dataset benchmarks. PromptAlign improves the generalization of CLIP at test time beyond existing prompt-tuning methods, achieving state-of-the-art results.

#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/PA.png" >
</p>
  <img src="images/TTIA/PA1.png" >
</p>
</details>
---

### `Diffusion-TTA` [Prabhudesai et al., **NeurIPS 2023**]  
**Test-time adaptation of discriminative models via diffusion generative feedback**  
[ğŸ“„ PDF](https://openreview.net/forum?id=gUTVpByfVX) Â· [ğŸ’» CODE](https://github.com/mihirp1998/Diffusion-TTA)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract  
The advancements in generative modeling, particularly the advent of diffusion models, have sparked a fundamental question: how can these models be effectively used for discriminative tasks? In this work, we find that generative models can be great test-time adapters for discriminative models. Our method, Diffusion-TTA, adapts pre-trained discriminative models such as image classifiers, segmenters and depth predictors, to each unlabelled example in the test set using generative feedback from a diffusion model. We achieve this by modulating the conditioning of the diffusion model using the output of the discriminative model. We then maximize the image likelihood objective by backpropagating the gradients to discriminative modelâ€™s parameters. We show Diffusion-TTA significantly enhances the accuracy of various large-scale pre-trained discriminative models, such as, ImageNet classifiers, CLIP models, image pixel labellers and image depth predictors. Diffusion-TTA outperforms existing test-time adaptation methods, including TTT-MAE and TENT, and particularly shines in online adaptation setups, where the discriminative model is continually adapted to each example in the test set. We provide access to code, results, and visualizations on our website: [diffusion-tta.github.io](https://diffusion-tta.github.io/).

#### ğŸ¯ Contributions  
We present Diffusion-based Test Time Adaptation (TTA) (Diffusion-TTA), a method that adapts discriminative models, such as image classifiers, segmenters and depth predictors, to individual unlabelled images by using their outputs to modulate the conditioning of an image diffusion model and maximize the image diffusion likelihood. This operates as an inversion of the generative model, to infer the discriminative weights that result in the discriminative hypothesis with the highest conditional image likelihood. Our model is reminiscent of an encoder-decoder architecture, where a pre-trained discriminative model encodes the image into a hypothesis, such as an object category label, segmentation map, or depth map, which is used as conditioning to a pre-trained generative model to generate back the image. We show that Diffusion-TTA effectively adapts image classifiers for both in- and out-of-distribution examples across established benchmarks, including ImageNet and its variants, as well as image segmenters and depth predictors in ADE20K and NYU Depth dataset.
#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/DTTA.png" >
</p>
  <img src="images/TTIA/DTTA1.png" >

</details>
---

### `DDA` [Gao et al., **CVPR 2023**]  
**Back to the source: Diffusion-driven adaptation to test-time corruption**  
[ğŸ“„ PDF](https://arxiv.org/abs/2207.03442) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=8145404192355562400&hl=en) Â· [ğŸ’» CODE](https://github.com/shiyegao/DDA)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract  
Test-time adaptation harnesses test inputs to improve the accuracy of a model trained on source data when tested on shifted target data. Most methods update the source model by (re-)training on each target domain. While re-training can help, it is sensitive to the amount and order of the data and the hyperparameters for optimization. We update the target data instead, and project all test inputs toward the source domain with a generative diffusion model. Our diffusion-driven adaptation (DDA) method shares its models for classification and generation across all domains, training both on source then freezing them for all targets, to avoid expensive domain-wise re-training. We augment diffusion with image guidance and classifier self-ensembling to automatically decide how much to adapt. Input adaptation by DDA is more robust than model adaptation across a variety of corruptions, models, and data regimes on the ImageNet-C benchmark. With its input-wise updates, DDA succeeds where model adaptation degrades on too little data (small batches), on dependent data (correlated orders), or on mixed data (multiple corruptions).

#### ğŸ¯ Contributions  
â€¢ We propose DDA as the first diffusion-based method for test-time adaptation to corruption and include a novel self-ensembling scheme to choose how much to adapt.  
â€¢ We identify and empirically confirm weak points for online model updatesâ€”small batches, ordered data, and mixed targetsâ€”and highlight how input updates address these natural but currently challenging regimes.  
â€¢ We experiment on the ImageNet-C benchmark to show that DDA improves over existing test-time adaptation methods across corruptions, models, and data regimes.

#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/DDA.png" >
</p>
  <img src="images/TTIA/DDA1.png" >
</p>
  <img src="images/TTIA/DDA2.png" >

</details>
---

### `IAI` [Jeon et al., **ICCV 2023**]  
**A unified framework for robustness on diverse sampling errors**  
[ğŸ“„ PDF](https://openaccess.thecvf.com/content/ICCV2023/html/Jeon_A_Unified_Framework_for_Robustness_on_Diverse_Sampling_Errors_ICCV_2023_paper.html) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=9460419101326058787&hl=en)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract  
Recent studies have substantiated that machine learning algorithms including convolutional neural networks often suffer from unreliable generalizations when there is a significant gap between the source and target data distributions. To mitigate this issue, a predetermined distribution shift has been addressed independently (e.g., single domain generalization, de-biasing). However, a distribution mismatch cannot be clearly estimated because the target distribution is unknown at training. Therefore, a conservative approach robust on unexpected diverse distributions is more desirable in practice. Our work starts from a motivation to allow adaptive inference once we know the target, since it is accessible only at testing. Instead of assuming and fixing the target distribution at training, our proposed approach allows adjusting the feature space the model refers to at every prediction, i.e., instance-wise adaptive inference. The extensive evaluation demonstrates our method is effective for generalization on diverse distributions.

#### ğŸ¯ Contributions  
â€¢ We present a novel framework for robust learning on arbitrary diverse distributions. This is desirable in scenarios where a model is deployed in a dynamic environment where queries often drift while the model cannot be frequently revised.  
â€¢ We propose a novel method that exploits adaptive inference re-weighting instance-wise on disentangled representations in widened feature space. Extensive evaluations demonstrate our method is robust on diverse distributions.
#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/IAI.png" >
</p>
  <img src="images/TTIA/IAI1.png" >
</p>
  <img src="images/TTIA/IAI2.png" >
  
</details>
---

### `TT-NSS` [Mehra et al., **ICML Workshops 2023**]  
**Risk-averse predictions on unseen domains via neural style smoothing**  
[ğŸ“„ PDF](https://openreview.net/forum?id=YVwW5yBISo)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract  
Achieving high accuracy on data from domains unseen during training is a fundamental challenge in machine learning. While state-of-the-art neural networks have achieved impressive performance on various tasks, their predictions are biased towards domain-dependent information (e.g., image styles) rather than domain-invariant information (e.g., image content). This makes them unreliable for deployment in risk-sensitive settings such as autonomous driving. In this work, we propose a novel inference procedure, Test-Time Neural Style Smoothing (TT-NSS), that produces risk-averse predictions using a â€œstyle smoothedâ€ version of a classifier. Specifically, the style-smoothed classifier classifies a test image as the most probable class predicted by the original classifier on random re-stylizations of the test image. TT-NSS uses a neural style transfer module to stylize the test image on the fly, requires black-box access to the classifier, and crucially, abstains when predictions of the original classifier on the stylized images lack consensus. We further propose a neural style smoothing-based training procedure that improves the prediction consistency and the performance of the style-smoothed classifier on non-abstained samples. Our experiments on the PACS dataset and its variations, both in single and multiple source domain settings, highlight the effectiveness of our methods at producing risk-averse predictions on unseen domains.

#### ğŸ¯ Contributions  
â€¢ We propose a simple and effective inference procedure based on neural style smoothing for obtaining risk-averse predictions. Our method returns the prediction of the style-smoothed classifier in real time with only black-box access to the underlying classifier.  
â€¢ We propose a novel training procedure to improve the performance of style-smoothed classifier by incorporating neural style smoothing during training and enforcing prediction consistency under random stylizations of the source domain data.  
â€¢ We evaluate the effectiveness of methods on benchmark datasets and their novel variations created by stylizing and applying common corruptions to them.

#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/TTNSS.png" >
</p>
  <img src="images/TTIA/TTNSS1.png" >
</details>  
---

### `GDA` [Tsai et al., **CVPR 2024**]  
**GDA: Generalized diffusion for robust test-time adaptation**  
[ğŸ“„ PDF](https://arxiv.org/abs/2404.00095) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=10549928891728768790&hl=en)
#### ğŸ§  Abstract  
Machine learning models face generalization challenges when exposed to out-of-distribution (OOD) samples with unforeseen distribution shifts. Recent research reveals that for vision tasks, test-time adaptation employing diffusion models can achieve state-of-the-art accuracy improvements on OOD samples by generating domain-aligned samples without altering the modelâ€™s weights. Unfortunately, those studies have primarily focused on pixel-level corruptions, thereby lacking the generalization to adapt to a broader range of OOD types. We introduce Generalized Diffusion Adaptation (GDA), a novel diffusion-based test-time adaptation method robust against diverse OOD types. Specifically, GDA iteratively guides the diffusion by applying a marginal entropy loss derived from the model, in conjunction with style and content preservation losses during the reverse sampling process. In other words, GDA considers the modelâ€™s output behavior and the samplesâ€™ semantic information as a whole, reducing ambiguity in downstream tasks. Evaluation across various model architectures and OOD benchmarks indicates that GDA consistently surpasses previous diffusion-based adaptation methods. Notably, it achieves the highest classification accuracy improvements, ranging from 4.4% to 5.02% on ImageNet-C and 2.5% to 7.4% on Rendition, Sketch, and Stylized benchmarks. This performance highlights GDAâ€™s generalization to a broader range of OOD benchmarks.

#### ğŸ¯ Contributions  
â€¢ We propose Generalized Diffusion Adaptation (GDA), a new diffusion-based adaptation method that generalizes to multiple local-texture and style-shifting OOD benchmarks, including ImageNet-C, Rendition, Sketch, and Stylized ImageNet.  
â€¢ Our key innovation is a new structural guidance towards minimizing marginal entropy, style, and content preservation loss. We demonstrate that our guidance is both effective and efficient as GDA reaches higher or on-par accuracy with fewer reverse sampling steps.  
â€¢ GDA outperforms state-of-the-art TTA methods, including DDA [5] and Diffpure [30] on four datasets with respect to target classifiers of different network backbones (ResNet50 [8], ConvNext [23], Swin [22], CLIP [34]).  
â€¢ Ablation studies show that GDA indeed minimizes the entropy loss, enhances the corrupted samples, and recovers the correct attention of the target classifier.

#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/GDA.png" >
</p>
  <img src="images/TTIA/GDA1.png" >
  </details>
---

### `MoDE` [Ma et al., **CVPR 2024**]  
**MoDE: CLIP data experts via clustering**  
[ğŸ“„ PDF](https://arxiv.org/abs/2404.16030) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=6687597386819654107&hl=en) Â· [ğŸ’» CODE](https://github.com/facebookresearch/MetaCLIP/tree/main/mode)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract  
The success of contrastive language-image pretraining (CLIP) relies on the supervision from the pairing between images and captions, which tends to be noisy in web-crawled data. We present Mixture of Data Experts (MoDE) and learn a system of CLIP data experts via clustering. Each data expert is trained on one data cluster, being less sensitive to false negative noises in other clusters. At inference time, we ensemble their outputs by applying weights determined through the correlation between task metadata and cluster conditions. To estimate the correlation precisely, the samples in one cluster should be semantically similar, but the number of data experts should still be reasonable for training and inference. As such, we consider the ontology in human language and propose to use fine-grained cluster centers to represent each data expert at a coarse-grained level. Experimental studies show that four CLIP data experts on ViT-B/16 outperform the ViT-L/14 by OpenAI CLIP and OpenCLIP on zero-shot image classification but with less (<35%) training cost. Meanwhile, MoDE can train all data expert asynchronously and can flexibly include new data experts. The code is available at: https://github.com/facebookresearch/MetaCLIP/tree/main/mode

#### ğŸ¯ Contributions  
â€¢ We investigate the quality of negative samples in contrastive language-image pretraining, and in particular, the noise of false negatives in web-crawled image-caption pairs.  
â€¢ We propose the MoDE framework to learn a system of CLIP data experts via clustering, and adaptively ensemble data experts for downstream tasks at inference time.  
â€¢ Extensive experimental study has demonstrated the effects in zero-shot transfer benchmarks with low training cost. MoDE can include new data experts flexibly and is thus beneficial for continual pre-training.

#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/MoDE.png" >
  </details>
---

### `CloudFixer` [Shim et al., **ECCV 2024**]  
**CloudFixer: Test-time adaptation for 3D point clouds via diffusion-guided geometric transformation**  
[ğŸ“„ PDF](https://arxiv.org/abs/2407.16193) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=4842877858434940251&hl=en) Â· [ğŸ’» CODE](https://github.com/shimazing/CloudFixer)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract  
3D point clouds captured from real-world sensors frequently encompass noisy points due to various obstacles, such as occlusion, limited resolution, and variations in scale. These challenges hinder the deployment of pre-trained point cloud recognition models trained on clean point clouds, leading to significant performance degradation. While test-time adaptation (TTA) strategies have shown promising results on this issue in the 2D domain, their application to 3D point clouds remains underexplored. Among TTA methods, an input adaptation approach, which directly converts test instances to the source domain using a pre-trained diffusion model, has been proposed in the 2D domain. Despite its robust TTA performance in practical situations, naively adopting this into the 3D domain may be suboptimal due to the neglect of inherent properties of point clouds, and its prohibitive computational cost. Motivated by these limitations, we propose **CloudFixer**, a test-time input adaptation method tailored for 3D point clouds, employing a pre-trained diffusion model. Specifically, CloudFixer optimizes geometric transformation parameters with carefully designed objectives that leverage the geometric properties of point clouds. We also substantially improve computational efficiency by avoiding backpropagation through the diffusion model and a prohibitive generation process. Furthermore, we propose an online model adaptation strategy by aligning the original model prediction with that of the adapted input. Extensive experiments showcase the superiority of CloudFixer over various TTA baselines, excelling in handling common corruptions and natural distribution shifts across diverse real-world scenarios. Our code is available at https://github.com/shimazing/CloudFixer.

#### ğŸ¯ Contributions  
â€¢ We propose **CloudFixer**, which is the first test-time input adaptation strategy tailored for 3D point clouds, proposing domain-specific parameterization and objective, harnessing pre-trained diffusion models.  
â€¢ CloudFixer is well-suited for real-time 3D applications as it requires neither backpropagation through the diffusion model nor an excessive generation process, enabling it to adapt a single instance in less than 1 second.  
â€¢ Through extensive experiments, we demonstrate that our method achieves state-of-the-art performance across diverse distribution shift scenarios, encompassing common corruptions and natural distribution shifts.

#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/CF.png" >
</details>
  ---

### `TPS` [Sui et al., **CVPR Workshops 2024**]  
**Just shift it: Test-time prototype shifting for zero-shot generalization with vision-language models**  
[ğŸ“„ PDF](https://arxiv.org/abs/2403.12952) Â· [ğŸ” G-Scholar](https://scholar.google.com/scholar?cluster=15629234813577501375&hl=en) Â· [ğŸ’» CODE](https://github.com/elaine-sui/TPS)
<details>
<summary>ğŸ“Œ Abstract Â· Contributions Â· Datasets & Methods</summary>
#### ğŸ§  Abstract  
Advancements in vision-language models (VLMs) have propelled the field of computer vision, particularly in the zero-shot learning setting. Despite their promise, the effectiveness of these models often diminishes due to domain shifts in test environments. To address this, we introduce the **Test-Time Prototype Shifting (TPS)** framework, a pioneering approach designed to adapt VLMs to test datasets using unlabeled test inputs. Our method is based on the notion of modulating per-class prototypes in the shared embedding space. By pre-computing and caching prototypes generated with the pre-trained text encoder, TPS not only facilitates optimization-free prototype reuse for subsequent predictions but also enables seamless integration with current advancements in prompt engineering. At test-time, TPS dynamically learns shift vectors for each prototype based solely on the given test sample, effectively bridging the domain gap and enhancing classification accuracy. A notable aspect of our framework is its significantly reduced memory and computational demands when compared to conventional text-prompt tuning methods. Extensive evaluations across 15 image classification datasets involving natural distribution shifts and cross-dataset generalization, as well as in context-dependent visual reasoning, demonstrate TPSâ€™s superior performance, achieving state-of-the-art results while reducing resource requirements. Code is available at: [https://github.com/elaine-sui/TPS](https://github.com/elaine-sui/TPS)

#### ğŸ¯ Contributions  
1. We introduce the **Test-Time Prototype Shifting (TPS)** framework, a novel, straightforward and efficient approach. This is, to our knowledge, the first instance of utilizing feature space modulation for test-time adaptation with VLMs.  
2. Our TPS framework seamlessly integrates with existing advancements in prompt engineering, transforming it into a flexible plug-and-play system.  
3. We achieve state-of-the-art performance on image classification on both natural distribution shift and cross-dataset generalization benchmarks, surpassing current SoTA by 3.3% and 1.9%, respectively, as well as context-dependent visual reasoning, surpassing SoTA TTA methods by 1.3%. Additionally, our approach significantly reduces computational and memory demands by more than 10Ã— compared to TPT.
#### ğŸ–¼ï¸ Method Overview
<p align="center">
  <img src="images/TTIA/TPS.png" >
</p>
  <img src="images/TTIA/TPS1.png" >
</p>
  <img src="images/TTIA/TPS2.png" >
</p>
</details>
---





